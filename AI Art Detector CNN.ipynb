{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Classifier\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Resizing, Conv2D, MaxPooling2D, Dense, Flatten, Rescaling, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from skimage import exposure\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training done with CPU. If CUDA and cuDNN are set up, a GPU can also be used to speed up model training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'TensorFlow Version: {tf.__version__}')\n",
    "print(tf.config.experimental.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory: str = 'data'\n",
    "batch_size: int = 32\n",
    "image_height: int = 256\n",
    "image_width: int = 256\n",
    "random_state: int = 111\n",
    "\n",
    "# True balances dataset to 10k of each class, false uses 20k generated images and 10k real images\n",
    "balance_dataset_TF: bool = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def load_dataset(dataset_dir):\n",
    "    '''\n",
    "    Loads and preprocesses image dataset. \n",
    "    Adjust preprocessing steps here and the preprocess_image function.\n",
    "    Requires only the image path. \n",
    "\n",
    "    Returns two arrays of the images and the labels. \n",
    "    '''\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(dataset_dir))\n",
    "    \n",
    "    for ii, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(dataset_dir, class_name)\n",
    "        for image_name in os.listdir(class_dir):\n",
    "            image_path = os.path.join(class_dir, image_name)\n",
    "            image = cv2.imread(image_path)  # Load image\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Make grayscale\n",
    "            image = cv2.resize(image, (image_height, image_width))  # Resize\n",
    "            #image = exposure.equalize_hist(image) # Histogram equalization\n",
    "            images.append(image)\n",
    "            labels.append(ii)  # Assign a label to the image based on the class index\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    '''\n",
    "    Loads and preprocesses a single image for classification.\n",
    "    Requires only the image path.\n",
    "    '''\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Make grayscale\n",
    "    image = cv2.resize(image, (image_height, image_width)) # Resize\n",
    "    image = exposure.equalize_hist(image) # Histogram equalization\n",
    "    return image \n",
    "    \n",
    "def balance_dataset(balance_dataset_TF, images, labels):\n",
    "    ''' \n",
    "    Optional: Randomly under sample majority class (AI-generated) for more balaanced dataset\n",
    "    Uses a random state from the global variable random_state.\n",
    "    Change balance_dataset_TF to True for balanced or False for imbalanced. \n",
    "\n",
    "    Returns either a balanced 50/50 dataset or the original 2/3 fake, 1/3 real dataset as arrays. \n",
    "    '''\n",
    "    if balance_dataset_TF == True:\n",
    "        indicies_of_majority_class = [x for x, label in enumerate(labels) if label == 0]\n",
    "        random.seed(random_state) # Set seed for reproducibility\n",
    "        random_indicies = random.sample(indicies_of_majority_class, 10000) # Randomly select 10000 fake images\n",
    "        random_undersampled_images = [images[index] for index in random_indicies]\n",
    "        random_undersampled_labels = [labels[index] for index in random_indicies]\n",
    "        \n",
    "        #Add back real images to randomly selected generated images\n",
    "        balanced_image_data = random_undersampled_images + [images[index] for index, label in enumerate(labels) if label == 1]\n",
    "        balanced_label_data = random_undersampled_labels + [label for label in labels if label == 1]\n",
    "        return np.array(balanced_image_data), np.array(balanced_label_data)\n",
    "    \n",
    "    elif balance_dataset_TF == False:\n",
    "        return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_dataset(data_directory)\n",
    "images, labels = balance_dataset(balance_dataset_TF, images, labels)\n",
    "print(f\"Images shape: {images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.3, random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CNN Model Using the Keras Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom architecture for baseline testing\n",
    "# Images can be any size\n",
    "\n",
    "model = Sequential([\n",
    "  Rescaling(1./255, input_shape=(image_height, image_width, 1)), # 1 at the end for Grayscale, 3 for RGB\n",
    "  Conv2D(16, 3, activation = 'relu'),\n",
    "  MaxPooling2D(),\n",
    "  Conv2D(32, 3, activation = 'relu'),\n",
    "  MaxPooling2D(),\n",
    "  Conv2D(32, 3, activation = 'relu'),\n",
    "  MaxPooling2D(),\n",
    "  Dropout(0.25),\n",
    "  Flatten(),\n",
    "  Dense(16, activation = 'relu'),\n",
    "  Dense(1, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = tf.losses.BinaryCrossentropy(), \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mimicking the LiNet CNN Architecture\n",
    "# Expects 233x233 images\n",
    "\n",
    "LiNet = Sequential([\n",
    "    # Layer 1\n",
    "    Conv2D(32, (7,7), padding = 'same', activation = 'relu', input_shape = (image_height, image_width, 1)),\n",
    "    \n",
    "    # Layer 2\n",
    "    Conv2D(64, (7,7), strides = 2, padding = 'same', activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(3, strides = 2, padding = 'same'),\n",
    "\n",
    "    # Layer 3\n",
    "    Conv2D(48, (5, 5), padding = 'same', activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((3, 3), strides = 2, padding = 'same'),\n",
    "\n",
    "    # Layer 4\n",
    "    Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((3, 3), strides = 2, padding = 'same'),\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    Flatten(),\n",
    "    Dense(4096, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation = 'softmax' )\n",
    "])\n",
    "\n",
    "LiNet.compile(optimizer = 'adam', \n",
    "              loss = tf.losses.BinaryCrossentropy(), \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "LiNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mimicking the AlexNet CNN Architecture\n",
    "# Expects 227x227 images\n",
    "\n",
    "AlexNet = Sequential([\n",
    "    Rescaling(1./255, input_shape = (image_height, image_width, 1)),\n",
    "\n",
    "    # Layer 1\n",
    "    Conv2D(96, (11, 11), strides = (4, 4), activation = 'relu', input_shape = (image_height, image_width, 1)), # 1 for Grayscale\n",
    "    MaxPooling2D((3, 3), strides = (2, 2)),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    # Layer 2\n",
    "    Conv2D(256, (5, 5), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D((3, 3), strides = (2, 2)),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    # Layer 3\n",
    "    Conv2D(384, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    Conv2D(384, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D((3, 3), strides = (2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "\n",
    "    # Fully connected layers\n",
    "    Dense(4096, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation = 'softmax')\n",
    "])\n",
    "\n",
    "AlexNet.compile(optimizer = 'adam',\n",
    "              loss = tf.losses.BinaryCrossentropy(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "AlexNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a pretrained model from TensorFlow called ResNet50\n",
    "# Expects 224x224 images\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "resnet_base = ResNet50(input_shape = (image_height, image_width, 3),\n",
    "                       include_top = False,\n",
    "                       weights = 'imagenet',\n",
    "                       classes = 2) # 1 for Grayscale\n",
    "\n",
    "# Prevent the pretrained layers from being overwritten\n",
    "resnet_base.trainable = False\n",
    "\n",
    "# Establish the ResNet model with custom Dense layer\n",
    "resnet_model = Sequential([\n",
    "    resnet_base,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1, activation = 'softmax') # Only need to train this layer\n",
    "    ])\n",
    "\n",
    "resnet_model.compile(optimizer = 'adam',\n",
    "              loss = tf.losses.BinaryCrossentropy(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Images need to be in a specific format for the ResNet model\n",
    "resnet_input_images = preprocess_input(images)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(resnet_input_images, labels, test_size = 0.3, random_state = random_state)\n",
    "\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell starts the training process and kicks off a TensorBoard instance for performance visualizations.\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs')\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'], color='teal', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the model architectures really learned how to distinguish between the two classes.\n",
    " \n",
    "The loss vs. validation and accuracy vs. validation accuracy were flat, showing no changes for any of the architectures. \n",
    "\n",
    "The models are not saved off because they are no better than randomly guessing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "\n",
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()\n",
    "\n",
    "for batch in X_test.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)\n",
    "\n",
    "\n",
    "print(pre.result(), re.result(), acc.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test-fake5.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (256,256))\n",
    "yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "if yhat > 0.5: \n",
    "    print(f'Predicted class is Real: {yhat}')\n",
    "else:\n",
    "    print(f'Predicted class is Fake: {yhat}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
