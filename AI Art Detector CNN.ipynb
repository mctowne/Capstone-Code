{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Classifiers\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Resizing, Conv2D, MaxPooling2D, Dense, Flatten, Rescaling, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import exposure\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training done with CPU. If CUDA and cuDNN are set up, a GPU can also be used to speed up model training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'TensorFlow Version: {tf.__version__}')\n",
    "print(tf.config.experimental.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory: str = 'data'\n",
    "batch_size: int = 32\n",
    "image_height: int = 256\n",
    "image_width: int = 256\n",
    "random_state: int = 111\n",
    "\n",
    "# True balances dataset to 10k of each class, false uses 20k generated images and 10k real images\n",
    "balance_dataset_TF: bool = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Helper Functions\n",
    "def plot_images(directory: list):\n",
    "    files = os.listdir(directory)\n",
    "    random_images = random.choices(files, k=9)\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    for ii in range(9):\n",
    "        image_path = os.path.join(directory, random_images[ii])  # File path\n",
    "        current_image = cv2.imread(image_path)\n",
    "        \n",
    "        # Add subplot\n",
    "        ax = fig.add_subplot(int(np.sqrt(9)), int(np.sqrt(9)), ii + 1)\n",
    "        \n",
    "        # Plot image\n",
    "        ax.imshow(current_image)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Display filename below the image\n",
    "        ax.set_title(random_images[ii], fontsize=6, pad=1, wrap = True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training paths\n",
    "train_dir = os.path.join('Y:/BACKUP Real_AI_SD_LD_Dataset/train')\n",
    "all_directories = os.listdir(train_dir)\n",
    "\n",
    "train_real = []\n",
    "train_ai = []\n",
    "\n",
    "for directory in all_directories:\n",
    "    if directory.startswith('AI_'):\n",
    "        train_ai.append(os.path.join(train_dir, directory))\n",
    "    else:\n",
    "        train_real.append(os.path.join(train_dir, directory))\n",
    "\n",
    "# Define the test paths\n",
    "test_dir = os.path.join('Y:/BACKUP Real_AI_SD_LD_Dataset/test')\n",
    "all_directories = os.listdir(test_dir)\n",
    "\n",
    "test_real = []\n",
    "test_ai = []\n",
    "\n",
    "for directory in all_directories:\n",
    "    if directory.startswith('AI_'):\n",
    "        test_ai.append(os.path.join(test_dir, directory))\n",
    "    else:\n",
    "        test_real.append(os.path.join(test_dir, directory))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying Real Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(train_real[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying Artificial Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(train_ai[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Data Frames with Directory Paths and Labels for Training and Testing\n",
    "\n",
    "##### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "for directory in train_real:\n",
    "    for file in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, file)\n",
    "        filepaths.append(filepath)\n",
    "        labels.append(\"real\")\n",
    "\n",
    "for directory in train_ai:\n",
    "    for file in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, file)\n",
    "        filepaths.append(filepath)\n",
    "        labels.append(\"AI\")\n",
    "\n",
    "train_data = pd.DataFrame(columns=['filepath', 'label'])\n",
    "\n",
    "data = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "\n",
    "train_data = pd.concat([train_data, data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "for directory in test_real:\n",
    "    for file in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, file)\n",
    "        filepaths.append(filepath)\n",
    "        labels.append(\"real\")\n",
    "\n",
    "for directory in test_ai:\n",
    "    for file in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, file)\n",
    "        filepaths.append(filepath)\n",
    "        labels.append(\"AI\")\n",
    "\n",
    "test_data = pd.DataFrame(columns=['filepath', 'label'])\n",
    "\n",
    "data = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "\n",
    "test_data = pd.concat([test_data, data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Random AI-Images to Balance the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)\n",
    "\n",
    "num_to_drop = 55015 #Gives the balanced dataset\n",
    "ai_indices = train_data[train_data['label'] == 'AI'].index\n",
    "indices_to_drop = np.random.choice(ai_indices, num_to_drop, replace=False)\n",
    "\n",
    "train_data = train_data.drop(indices_to_drop)\n",
    "train_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Training Set and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "training_generator = ImageDataGenerator(rescale=1./255,   # Normalize pixel value\n",
    "                                       # rotation_range=7, # Apply rotations to the image\n",
    "                                       # horizontal_flip=True, # Flip image horizontally\n",
    "                                       # zoom_range=0.2  # Increase and decrease zoom by 0.2x\n",
    "                                       )\n",
    "train_dataset = training_generator.flow_from_dataframe(dataframe=train_data,\n",
    "                                                       x_col='filepath',\n",
    "                                                       y_col='label',\n",
    "                                                       target_size=(image_height, image_width),\n",
    "                                                       batch_size=64,\n",
    "                                                       class_mode='categorical',  \n",
    "                                                       shuffle=True)\n",
    "#Testing\n",
    "test_generator = ImageDataGenerator(rescale=1./255 # Normalize pixel value\n",
    "                                    # rotation_range=7, # Apply rotations to the image\n",
    "                                    # horizontal_flip=True, # Flip image horizontally\n",
    "                                    # zoom_range=0.2  # Increase and decrease zoom by 0.2x\n",
    "                                    )\n",
    "test_dataset = test_generator.flow_from_dataframe(dataframe=test_data,\n",
    "                                                  x_col='filepath',\n",
    "                                                  y_col='label',\n",
    "                                                  target_size = (image_height, image_width),\n",
    "                                                  batch_size = 1,    # 1 image at a time to evaluate the NN\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  shuffle = False)   # to associate the prediction with expected output\n",
    "\n",
    "print(train_dataset.class_indices)\n",
    "print(test_dataset.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CNN Model Using the Keras Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom architecture for baseline testing\n",
    "# Images can be any size\n",
    "\n",
    "model = Sequential([\n",
    "  Conv2D(filters = 64, kernel_size = 3, input_shape = (256,256,3), activation = 'relu'),\n",
    "  MaxPooling2D(),\n",
    "  Conv2D(filters = 64, kernel_size = 3, activation = 'relu'),\n",
    "  MaxPooling2D(),\n",
    "  Flatten(),\n",
    "  Dense(units = 64, activation = 'relu'),\n",
    "  Dense(units = 2, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'Adam', \n",
    "              loss = tf.losses.BinaryCrossentropy(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mimicking the LiNet CNN Architecture\n",
    "# Expects 233x233 images\n",
    "\n",
    "LiNet = Sequential([\n",
    "    # Layer 1\n",
    "    Conv2D(32, (7,7), padding = 'same', activation = 'relu', input_shape = (image_height, image_width, 1)),\n",
    "    \n",
    "    # Layer 2\n",
    "    Conv2D(64, (7,7), strides = 2, padding = 'same', activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(3, strides = 2, padding = 'same'),\n",
    "\n",
    "    # Layer 3\n",
    "    Conv2D(48, (5, 5), padding = 'same', activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((3, 3), strides = 2, padding = 'same'),\n",
    "\n",
    "    # Layer 4\n",
    "    Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((3, 3), strides = 2, padding = 'same'),\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    Flatten(),\n",
    "    Dense(4096, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation = 'softmax' )\n",
    "])\n",
    "\n",
    "LiNet.compile(optimizer = 'adam', \n",
    "              loss = tf.losses.BinaryCrossentropy(), \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "LiNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mimicking the AlexNet CNN Architecture\n",
    "# Expects 227x227 images\n",
    "\n",
    "AlexNet = Sequential([\n",
    "    Rescaling(1./255, input_shape = (image_height, image_width, 1)),\n",
    "\n",
    "    # Layer 1\n",
    "    Conv2D(96, (11, 11), strides = (4, 4), activation = 'relu', input_shape = (image_height, image_width, 1)), # 1 for Grayscale\n",
    "    MaxPooling2D((3, 3), strides = (2, 2)),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    # Layer 2\n",
    "    Conv2D(256, (5, 5), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D((3, 3), strides = (2, 2)),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    # Layer 3\n",
    "    Conv2D(384, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    Conv2D(384, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D((3, 3), strides = (2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "\n",
    "    # Fully connected layers\n",
    "    Dense(4096, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation = 'softmax')\n",
    "])\n",
    "\n",
    "AlexNet.compile(optimizer = 'adam',\n",
    "              loss = tf.losses.BinaryCrossentropy(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "AlexNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a pretrained model from TensorFlow called ResNet50\n",
    "# Expects 224x224 images\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "resnet_base = ResNet50(input_shape = (image_height, image_width, 3),\n",
    "                       include_top = False,\n",
    "                       weights = 'imagenet',\n",
    "                       classes = 2) # 1 for Grayscale\n",
    "\n",
    "# Prevent the pretrained layers from being overwritten\n",
    "resnet_base.trainable = False\n",
    "\n",
    "# Establish the ResNet model with custom Dense layer\n",
    "resnet_model = Sequential([\n",
    "    resnet_base,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1, activation = 'softmax') # Only need to train this layer\n",
    "    ])\n",
    "\n",
    "resnet_model.compile(optimizer = 'adam',\n",
    "              loss = tf.losses.BinaryCrossentropy(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Images need to be in a specific format for the ResNet model\n",
    "resnet_input_images = preprocess_input(images)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(resnet_input_images, labels, test_size = 0.3, random_state = random_state)\n",
    "\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell starts the training process and kicks off a TensorBoard instance for performance visualizations.\n",
    "\n",
    "# Baseline, simple model\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs')\n",
    "history = model.fit(train_dataset, epochs=10, validation_data=test_dataset, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'], color='teal', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "\n",
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()\n",
    "\n",
    "for batch in X_test.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)\n",
    "\n",
    "\n",
    "print(pre.result(), re.result(), acc.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test-fake5.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (256,256))\n",
    "yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "if yhat > 0.5: \n",
    "    print(f'Predicted class is Real: {yhat}')\n",
    "else:\n",
    "    print(f'Predicted class is Fake: {yhat}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
